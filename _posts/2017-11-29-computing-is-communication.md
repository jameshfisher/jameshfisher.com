---
title: "Computing is communication"
draft: true
---

There is a standard history of computing which runs like this:

    The devices we own - laptops, phones - are all computers.
    These devices can do many things, but their core strength is _computation_.
    Not so long ago, "computers" were people, and they computed things for you.
    They began to use tools to aid them, like the abacus.
    In the 19th century, Babbage created the difference and analytical engines.
    In the 1890s, Hollerith made punched cards and worked out how to sort them electronically.
    In the 1930s/40s, we got two theoretical models of computing: the Turing machine and the lambda calculus.
    The mid-20th century saw the first computers with components like today's, e.g. the 1946 ENIAC.
    Since then, computers have become a _lot_ smaller, and now they fit in your hand!
    Today, most people have several computers,
    and they are linked together by many kinds of network, allowing their users to communicate.

I think this history has the wrong emphasis. 
An alternative history runs like this:

    The devices we all own - laptops, phones - are all communicators.
    They can do many things, but their core strength is _communication_.
    Not so long ago, communicators were people, and they delivered messages for you.
    They began to use tools to aid them.
    Telegraph, telegram, telephone.
    Early telegraphy required a human to receive the messages. Later receivers got printers.
    Early telephone systems required human switchboard operators; the caller would describe the recipient.
    Automatic switchboards in the early 20th century introduced more sophisticated switchboards and telephones with dialers.
    Automatic switchboards became electronic around 1950/60. These were stored-program controllers.
    Radio, television.
    In the 1870s, the telephone was invented.
    Electronic communicators were extremely important in WWII (the most famous being the Enigma).
    In 1948, Shannon formalized "information", as a way to understand modern communication.
    Mobile phone 1973.
    Internet, 1970s+.
    In the 1970s, communication was secured by cryptography.
    Today's communicators can also do powerful calculation.

These devices have at least two (interconnected) abilities: 
computation (rearrangement of data) and communication (movement of data). 
One might also add storage of data 
(though this could be viewed as communication with the future, or a buffer).

In our devices, the CPU and memory roughly correspond to Turing's machine. 
Pretty much everything else is communication-oriented. 
Keyboard, mouse, screen, touchscreen, microphone, speaker, graphics card, sound card, ethernet card, WiFi module, bluetooth, DSP chips, audio/video codec chips, GSM and all the other mobile comms chips, webcam, camera. 
There is certainly "computing" in all this hardware, 
but it's all in the name of communication.

Today's large companies are communication platforms. 
Facebook is obvious. 
Google helps people communicate their message, and helps others find the message. 
Web is mostly advertising, which is just more communication. 
Many of today's startups are advances in communication, not computation. 
Uber, AirBnb, and all the other gig markets are primarily communication platforms.

Why the bias towards "computation" in our histories?

There is a bias towards a mathematical notion of computation. 
The mathematical notion of computation suggests that 
"computers" are all the same 
and thus the IBM tabulator is morally equivalent to today's smartphone. 
It is not. 
A history of computing should acknowledge the physicality of devices and their purpose. 
A history of computing should acknowledge step changes in device abilities: 
audio, video, mobile.

The mainstream history of computing says: 
we discover a universal idea of computation, 
but we learn to do it smaller, faster, cheaper.

In "teaching computing", 
we bias towards learning computation instead of communication. 
There are people who know many programming languages, yet no protocols. 
Communication is relegated to a "networking" module in a "computing science" degree.

A key problem is terminology. 
The term "computing" is overloaded: 
we use it to refer to a mathematical notion of "computation", 
as well as to refer to a broad class of devices such as our laptops, phones, and watches.

In _Code_, he describes how "computers" are built of RELAYS.
The relay is the fundamental communicator.
Computation is built from communication.
